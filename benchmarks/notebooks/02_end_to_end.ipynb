{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91c52cd8",
   "metadata": {},
   "source": [
    "# End-to-End Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a560a2",
   "metadata": {},
   "source": [
    "Run QuASAr and baseline backends on benchmark circuits and compare performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd7de37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath('../..'))\n",
    "import pandas as pd\n",
    "from benchmarks.runner import BenchmarkRunner\n",
    "from benchmarks.backends import StatevectorAdapter, DecisionDiagramAdapter, MPSAdapter, StimAdapter\n",
    "from benchmarks import circuits\n",
    "from quasar.simulation_engine import SimulationEngine\n",
    "from quasar_convert import ConversionEngine\n",
    "import time, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackingConversionEngine(ConversionEngine):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.total_time = 0.0\n",
    "    def _timeit(self, func, *args, **kwargs):\n",
    "        start = time.perf_counter()\n",
    "        res = func(*args, **kwargs)\n",
    "        self.total_time += time.perf_counter() - start\n",
    "        return res\n",
    "    def convert_boundary_to_statevector(self, ssd):\n",
    "        return self._timeit(super().convert_boundary_to_statevector, ssd)\n",
    "    def convert_boundary_to_tableau(self, ssd):\n",
    "        if hasattr(super(), \"convert_boundary_to_tableau\"):\n",
    "            return self._timeit(super().convert_boundary_to_tableau, ssd)\n",
    "        raise AttributeError\n",
    "    def convert_boundary_to_dd(self, ssd):\n",
    "        if hasattr(super(), \"convert_boundary_to_dd\"):\n",
    "            return self._timeit(super().convert_boundary_to_dd, ssd)\n",
    "        raise AttributeError\n",
    "    def extract_local_window(self, state, qubits):\n",
    "        return self._timeit(super().extract_local_window, state, qubits)\n",
    "    def build_bridge_tensor(self, left, right):\n",
    "        return self._timeit(super().build_bridge_tensor, left, right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbea786",
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit_fns = {\n",
    "    'ghz': circuits.ghz_circuit,\n",
    "    'qft': circuits.qft_circuit,\n",
    "    'w_state': circuits.w_state_circuit,\n",
    "    'grover': circuits.grover_circuit,\n",
    "}\n",
    "backends = {\n",
    "    'statevector': StatevectorAdapter(),\n",
    "    'mqt_dd': DecisionDiagramAdapter(),\n",
    "    'mps': MPSAdapter(),\n",
    "    'stim': StimAdapter(),\n",
    "}\n",
    "REPETITIONS = 5\n",
    "NUM_QUBITS = 2\n",
    "records = []\n",
    "for cname, cfn in circuit_fns.items():\n",
    "    circuit = cfn(NUM_QUBITS)\n",
    "    for bname, backend in backends.items():\n",
    "        for _ in range(REPETITIONS):\n",
    "            runner = BenchmarkRunner()\n",
    "            try:\n",
    "                rec = runner.run_multiple(circuit, backend, return_state=False, repetitions=3)\n",
    "            except (NotImplementedError, RuntimeError):\n",
    "                continue\n",
    "            rec.update({'circuit': cname, 'backend_switches': 0, 'conversion_time': 0.0})\n",
    "            records.append(rec)\n",
    "    for _ in range(REPETITIONS):\n",
    "        ce = TrackingConversionEngine()\n",
    "        runner = BenchmarkRunner()\n",
    "        engine = SimulationEngine(conversion_engine=ce)\n",
    "        rec = runner.run_quasar(circuit, engine)\n",
    "        rec.update({'circuit': cname,\n",
    "                    'backend_switches': len(rec['result'].conversions),\n",
    "                    'conversion_time': ce.total_time})\n",
    "        records.append(rec)\n",
    "df = pd.DataFrame(records)\n",
    "df['runtime'] = df['total_time_mean'].fillna(df['total_time'])\n",
    "df['peak_memory'] = df[['prepare_peak_memory', 'run_peak_memory', 'prepare_peak_memory_mean', 'run_peak_memory_mean']].max(axis=1)\n",
    "summary = df.groupby(['circuit','framework']).agg(\n",
    "    runtime_mean=('runtime','mean'), runtime_std=('runtime','std'),\n",
    "    peak_memory_mean=('peak_memory','mean'), peak_memory_std=('peak_memory','std'),\n",
    "    backend_switches_mean=('backend_switches','mean'),\n",
    "    backend_switches_std=('backend_switches','std'),\n",
    "    conversion_time_mean=('conversion_time','mean'),\n",
    "    conversion_time_std=('conversion_time','std')\n",
    ").reset_index()\n",
    "ghz_backend = df[(df.circuit == 'ghz') & (df.framework == 'quasar')]['backend'].unique()\n",
    "assert len(ghz_backend) == 1 and ghz_backend[0].lower() in {'stim', 'tableau'}, f'GHZ routed to {ghz_backend}'\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "runtime_mean = summary.pivot(index='circuit', columns='framework', values='runtime_mean')\n",
    "runtime_std = summary.pivot(index='circuit', columns='framework', values='runtime_std')\n",
    "ax = runtime_mean.plot.bar(yerr=runtime_std, capsize=4)\n",
    "ax.set_ylabel('Runtime (s)')\n",
    "ax.set_xlabel('Circuit')\n",
    "plt.tight_layout()\n",
    "\n",
    "peak_mean = summary.pivot(index='circuit', columns='framework', values='peak_memory_mean')\n",
    "peak_std = summary.pivot(index='circuit', columns='framework', values='peak_memory_std')\n",
    "ax = peak_mean.plot.bar(yerr=peak_std, capsize=4)\n",
    "ax.set_ylabel('Peak memory (B)')\n",
    "ax.set_xlabel('Circuit')\n",
    "plt.tight_layout()\n"
   ],
   "outputs": [],
   "execution_count": 0
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd6aa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "speedup = []\n",
    "for cname in circuit_fns:\n",
    "    quasar_time = summary[(summary.circuit==cname)&(summary.framework=='quasar')]['runtime_mean'].iloc[0]\n",
    "    baseline_times = summary[(summary.circuit==cname)&(summary.framework!='quasar')]['runtime_mean']\n",
    "    if not baseline_times.empty:\n",
    "        best_baseline = baseline_times.min()\n",
    "        speedup.append({'circuit': cname, 'speedup': best_baseline/quasar_time})\n",
    "speedup_df = pd.DataFrame(speedup)\n",
    "speedup_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4e4c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = speedup_df.plot.bar(x='circuit', y='speedup', legend=False)\n",
    "ax.set_ylabel('QuASAr speedup over best baseline')\n",
    "ax.set_xlabel('Circuit')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bf2cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from benchmarks.stats_utils import stats_table\n",
    "\n",
    "def add_stats(df, quasar_col='QuASAr', baseline_cols=None, test='ttest', correction='bonferroni'):\n",
    "    \"\"\"Compute statistics comparing QuASAr with baselines.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with per-circuit results. One column must correspond to QuASAr,\n",
    "        others to baselines.\n",
    "    quasar_col : str\n",
    "        Name of the column containing QuASAr results.\n",
    "    baseline_cols : list[str] | None\n",
    "        Columns to treat as baselines. Defaults to all columns except quasar_col.\n",
    "    test : str\n",
    "        'ttest' or 'wilcoxon'.\n",
    "    correction : str\n",
    "        'bonferroni' or 'fdr_bh'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Table with baseline name, statistic, corrected p-value, and effect size.\n",
    "    \"\"\"\n",
    "    if baseline_cols is None:\n",
    "        baseline_cols = [c for c in df.columns if c != quasar_col]\n",
    "    baselines = {c: df[c] for c in baseline_cols}\n",
    "    return stats_table(df[quasar_col], baselines, test=test, correction=correction)\n",
    "\n",
    "# Example usage after computing results DataFrame named `results_df`:\n",
    "# stats_df = add_stats(results_df)\n",
    "# stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cbf895",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Record parameters and results\n",
    "import json, pathlib\n",
    "try:\n",
    "    import ipynbname\n",
    "    nb_name = ipynbname.path().stem\n",
    "except Exception:  # pragma: no cover\n",
    "    nb_name = 'notebook'\n",
    "\n",
    "# Collect simple parameters from globals\n",
    "_params = {\n",
    "    k: v for k, v in globals().items()\n",
    "    if not k.startswith('_') and isinstance(v, (int, float, str, bool, list, dict, tuple))\n",
    "}\n",
    "pathlib.Path('../results').mkdir(exist_ok=True)\n",
    "with open(f\"../results/{nb_name}_params.json\", 'w') as f:\n",
    "    try:\n",
    "        json.dump(_params, f, indent=2)\n",
    "    except TypeError:\n",
    "        pass\n",
    "if 'results' in globals():\n",
    "    try:\n",
    "        with open(f\"../results/{nb_name}_results.json\", 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "    except TypeError:\n",
    "        pass\n",
    "try:\n",
    "    print(json.dumps(_params, indent=2))\n",
    "except TypeError:\n",
    "    print(_params)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}