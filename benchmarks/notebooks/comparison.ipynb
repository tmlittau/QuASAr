{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "21b8aac9",
   "metadata": {},
   "source": [
    "# Benchmark Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5755f2e7",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to run benchmarks using the command line interface and visualize the results. It additionally compares QuASAr's native backends with external simulators from Qiskit Aer and MQT DD.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d93ff9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import sys\n",
    "import subprocess\n",
    "import tempfile\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "sns.set_theme()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde3bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = Path(tempfile.gettempdir())/\"quasar_cli_example\"\n",
    "subprocess.run([sys.executable, \"../benchmark_cli.py\", \"--circuit\", \"ghz\", \"--qubits\", \"2:5\", \"--repetitions\", \"2\", \"--output\", str(tmp)], check=True)\n",
    "\n",
    "cli_df = pd.read_csv(tmp.with_suffix(\".csv\"))\n",
    "\n",
    "cli_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabdb996",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=cli_df, x=\"qubits\", y=\"avg_time\", marker=\"o\")\n",
    "plt.title(\"GHZ circuit benchmark\")\n",
    "plt.xlabel(\"Qubits\")\n",
    "plt.ylabel(\"Average time (s)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f003844",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_root = Path('..' ).resolve()\n",
    "sys.path.append(str(nb_root))\n",
    "sys.path.append(str(nb_root.parent))\n",
    "\n",
    "from runner import BenchmarkRunner\n",
    "from backends import (\n",
    "    StatevectorAdapter,\n",
    "    StimAdapter,\n",
    "    MPSAdapter,\n",
    "    DecisionDiagramAdapter,\n",
    ")\n",
    "import circuits as circuit_lib\n",
    "from quasar import SimulationEngine\n",
    "from quasar.cost import Backend\n",
    "\n",
    "backends = [StatevectorAdapter()]\n",
    "runner = BenchmarkRunner()\n",
    "engine = SimulationEngine()\n",
    "\n",
    "backend_map = {\n",
    "    'statevector': Backend.STATEVECTOR,\n",
    "    'stim': Backend.TABLEAU,\n",
    "    'mps': Backend.MPS,\n",
    "    'mqt_dd': Backend.DECISION_DIAGRAM,\n",
    "}\n",
    "\n",
    "circuits = {\n",
    "    'ghz': circuit_lib.ghz_circuit,\n",
    "    'qft': circuit_lib.qft_circuit,\n",
    "}\n",
    "\n",
    "qubit_sizes = list(range(2, 6))\n",
    "\n",
    "for name, build in circuits.items():\n",
    "    for n in qubit_sizes:\n",
    "        try:\n",
    "            circ = build(n)\n",
    "        except Exception:\n",
    "            continue\n",
    "        for b in backends:\n",
    "            try:\n",
    "                rec = runner.run_multiple(circ, b, return_state=False, repetitions=3)\n",
    "                rec['circuit'] = name\n",
    "                rec['qubits'] = n\n",
    "                rec['backend'] = b.name\n",
    "            except Exception:\n",
    "                pass\n",
    "            try:\n",
    "                rec = runner.run_quasar_multiple(\n",
    "                    circ,\n",
    "                    engine,\n",
    "                    backend=backend_map.get(b.name),\n",
    "                    repetitions=3,\n",
    "                )\n",
    "                rec['circuit'] = name\n",
    "                rec['qubits'] = n\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "\n",
    "df = pd.DataFrame(runner.results)\n",
    "df_long = df.melt(\n",
    "    id_vars=['circuit', 'framework', 'backend', 'qubits'],\n",
    "    value_vars=['prepare_time_mean', 'run_time_mean'],\n",
    "    var_name='phase',\n",
    "    value_name='time',\n",
    ")\n",
    "g = sns.relplot(\n",
    "    data=df_long,\n",
    "    x='qubits',\n",
    "    y='time',\n",
    "    hue='framework',\n",
    "    style='phase',\n",
    "    col='circuit',\n",
    "    col_wrap=3,\n",
    "    kind='line',\n",
    ")\n",
    "g.set(yscale='log')\n",
    "plt.show()\n",
    "df[['circuit', 'framework', 'backend', 'qubits', 'prepare_time_mean', 'run_time_mean', 'total_time_mean']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e71e538",
   "metadata": {},
   "source": [
    "These results separate the **preparation** time from the actual **simulation** run time. Preparation typically includes converting circuits or planning steps, whereas simulation measures the time spent executing the circuit. The table and plot above illustrate how both components contribute to the total runtime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd6f198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from benchmarks.stats_utils import stats_table\n",
    "\n",
    "def add_stats(df, quasar_col='QuASAr', baseline_cols=None, test='ttest', correction='bonferroni'):\n",
    "    \"\"\"Compute statistics comparing QuASAr with baselines.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        DataFrame with per-circuit results. One column must correspond to QuASAr,\n",
    "        others to baselines.\n",
    "    quasar_col : str\n",
    "        Name of the column containing QuASAr results.\n",
    "    baseline_cols : list[str] | None\n",
    "        Columns to treat as baselines. Defaults to all columns except quasar_col.\n",
    "    test : str\n",
    "        'ttest' or 'wilcoxon'.\n",
    "    correction : str\n",
    "        'bonferroni' or 'fdr_bh'.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame\n",
    "        Table with baseline name, statistic, corrected p-value, and effect size.\n",
    "    \"\"\"\n",
    "    if baseline_cols is None:\n",
    "        baseline_cols = [c for c in df.columns if c != quasar_col]\n",
    "    baselines = {c: df[c] for c in baseline_cols}\n",
    "    return stats_table(df[quasar_col], baselines, test=test, correction=correction)\n",
    "\n",
    "# Example usage after computing results DataFrame named `results_df`:\n",
    "# stats_df = add_stats(results_df)\n",
    "# stats_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e767c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Record parameters and results\n",
    "import json, pathlib\n",
    "try:\n",
    "    import ipynbname\n",
    "    nb_name = ipynbname.path().stem\n",
    "except Exception:  # pragma: no cover\n",
    "    nb_name = 'notebook'\n",
    "\n",
    "# Collect simple parameters from globals\n",
    "_params = {\n",
    "    k: v for k, v in globals().items()\n",
    "    if not k.startswith('_') and isinstance(v, (int, float, str, bool, list, dict, tuple))\n",
    "}\n",
    "pathlib.Path('../results').mkdir(exist_ok=True)\n",
    "with open(f'../results/{nb_name}_params.json', 'w') as f:\n",
    "    json.dump(_params, f, indent=2, default=str)\n",
    "if 'results' in globals():\n",
    "    try:\n",
    "        with open(f'../results/{nb_name}_results.json', 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(json.dumps(_params, indent=2, default=str))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
