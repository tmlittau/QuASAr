{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bdc5e85",
   "metadata": {},
   "source": [
    "# Parallelism Benchmarks\n",
    "This notebook illustrates the effect of enabling scheduler parallel execution across backends using real simulators.",
    "\n\nFigures are saved to `../figures/` and tables to `../results/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "FIGURES_DIR = Path('../figures')\n",
    "RESULTS_DIR = Path('../results')\n",
    "FIGURES_DIR.mkdir(exist_ok=True)\n",
    "RESULTS_DIR.mkdir(exist_ok=True)\n",
    "try:\n",
    "    import ipynbname\n",
    "    NB_NAME = ipynbname.path().stem\n",
    "except Exception:  # pragma: no cover\n",
    "    NB_NAME = 'notebook'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f47b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from quasar import Circuit, Scheduler\n",
    "from quasar.cost import Backend\n",
    "from quasar.backends import StimBackend, MPSBackend\n",
    "from quasar.planner import Planner\n",
    "from benchmarks.runner import BenchmarkRunner\n",
    "import quasar.config as config\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "config.DEFAULT.dd_metric_threshold = 999  # disable decision-diagram backend\n",
    "\n",
    "runner = BenchmarkRunner()\n",
    "\n",
    "\n",
    "def stim_circuit(reps: int = 500) -> Circuit:\n",
    "    ops = []\n",
    "    for _ in range(reps):\n",
    "        ops.extend([\n",
    "            {\"gate\": \"H\", \"qubits\": [0]},\n",
    "            {\"gate\": \"H\", \"qubits\": [1]},\n",
    "            {\"gate\": \"CX\", \"qubits\": [0, 1]},\n",
    "            {\"gate\": \"H\", \"qubits\": [2]},\n",
    "            {\"gate\": \"H\", \"qubits\": [3]},\n",
    "            {\"gate\": \"CX\", \"qubits\": [2, 3]},\n",
    "        ])\n",
    "    return Circuit(ops)\n",
    "\n",
    "\n",
    "def mps_circuit(reps: int = 100) -> Circuit:\n",
    "    ops = []\n",
    "    for _ in range(reps):\n",
    "        ops.extend([\n",
    "            {\"gate\": \"H\", \"qubits\": [0]},\n",
    "            {\"gate\": \"T\", \"qubits\": [0]},\n",
    "            {\"gate\": \"CX\", \"qubits\": [0, 1]},\n",
    "            {\"gate\": \"H\", \"qubits\": [2]},\n",
    "            {\"gate\": \"T\", \"qubits\": [2]},\n",
    "            {\"gate\": \"CX\", \"qubits\": [2, 3]},\n",
    "        ])\n",
    "    return Circuit(ops)\n",
    "\n",
    "stim = stim_circuit()\n",
    "mps = mps_circuit()\n",
    "\n",
    "# Stim benchmarks\n",
    "scheduler_stim_parallel = Scheduler(\n",
    "    backends={Backend.TABLEAU: StimBackend()},\n",
    "    planner=Planner(backend_order=[Backend.TABLEAU]),\n",
    "    parallel_backends=[Backend.TABLEAU],\n",
    "    quick_max_qubits=None,\n",
    "    quick_max_gates=None,\n",
    "    quick_max_depth=None,\n",
    ")\n",
    "\n",
    "scheduler_stim_serial = Scheduler(\n",
    "    backends={Backend.TABLEAU: StimBackend()},\n",
    "    planner=Planner(backend_order=[Backend.TABLEAU]),\n",
    "    parallel_backends=[],\n",
    "    quick_max_qubits=None,\n",
    "    quick_max_gates=None,\n",
    "    quick_max_depth=None,\n",
    ")\n",
    "\n",
    "res_stim_parallel = runner.run_quasar(stim, scheduler_stim_parallel, backend=Backend.TABLEAU)\n",
    "res_stim_serial = runner.run_quasar(stim, scheduler_stim_serial, backend=Backend.TABLEAU)\n",
    "\n",
    "# MPS benchmarks\n",
    "scheduler_mps_parallel = Scheduler(\n",
    "    backends={Backend.MPS: MPSBackend()},\n",
    "    planner=Planner(backend_order=[Backend.MPS]),\n",
    "    parallel_backends=[Backend.MPS],\n",
    "    quick_max_qubits=None,\n",
    "    quick_max_gates=None,\n",
    "    quick_max_depth=None,\n",
    ")\n",
    "\n",
    "scheduler_mps_serial = Scheduler(\n",
    "    backends={Backend.MPS: MPSBackend()},\n",
    "    planner=Planner(backend_order=[Backend.MPS]),\n",
    "    parallel_backends=[],\n",
    "    quick_max_qubits=None,\n",
    "    quick_max_gates=None,\n",
    "    quick_max_depth=None,\n",
    ")\n",
    "\n",
    "res_mps_parallel = runner.run_quasar(mps, scheduler_mps_parallel, backend=Backend.MPS)\n",
    "res_mps_serial = runner.run_quasar(mps, scheduler_mps_serial, backend=Backend.MPS)\n",
    "\n",
    "\n",
    "df = pd.DataFrame([\n",
    "    {\"backend\": \"Stim\", \"mode\": \"serial\", \"runtime\": res_stim_serial[\"run_time\"], \"memory\": res_stim_serial[\"run_peak_memory\"]},\n",
    "    {\"backend\": \"Stim\", \"mode\": \"parallel\", \"runtime\": res_stim_parallel[\"run_time\"], \"memory\": res_stim_parallel[\"run_peak_memory\"]},\n",
    "    {\"backend\": \"MPS\", \"mode\": \"serial\", \"runtime\": res_mps_serial[\"run_time\"], \"memory\": res_mps_serial[\"run_peak_memory\"]},\n",
    "    {\"backend\": \"MPS\", \"mode\": \"parallel\", \"runtime\": res_mps_parallel[\"run_time\"], \"memory\": res_mps_parallel[\"run_peak_memory\"]},\n",
    "])\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9e44be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "df.pivot(index=\"backend\", columns=\"mode\", values=\"runtime\").plot.bar(ax=axes[0])\n",
    "axes[0].set_ylabel(\"Runtime (s)\")\n",
    "df.pivot(index=\"backend\", columns=\"mode\", values=\"memory\").plot.bar(ax=axes[1])\n",
    "axes[1].set_ylabel(\"Peak memory (bytes)\")\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ecf38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stim_speedup = res_stim_serial[\"run_time\"] / res_stim_parallel[\"run_time\"] if res_stim_parallel[\"run_time\"] > 0 else float('inf')\n",
    "mps_speedup = res_mps_serial[\"run_time\"] / res_mps_parallel[\"run_time\"] if res_mps_parallel[\"run_time\"] > 0 else float('inf')\n",
    "print(f\"Stim parallel {res_stim_parallel['run_time']:.3f}s vs serial {res_stim_serial['run_time']:.3f}s -> {stim_speedup:.2f}x speedup\")\n",
    "print(f\"Stim memory parallel {res_stim_parallel['run_peak_memory']}B vs serial {res_stim_serial['run_peak_memory']}B\")\n",
    "print(f\"MPS parallel {res_mps_parallel['run_time']:.3f}s vs serial {res_mps_serial['run_time']:.3f}s -> {mps_speedup:.2f}x speedup\")\n",
    "print(f\"MPS memory parallel {res_mps_parallel['run_peak_memory']}B vs serial {res_mps_serial['run_peak_memory']}B\")\n",
    "results = df.to_dict(orient='records')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75c6266",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Record parameters and results\n",
    "import json, pathlib\n",
    "try:\n",
    "    import ipynbname\n",
    "    nb_name = ipynbname.path().stem\n",
    "except Exception:  # pragma: no cover\n",
    "    nb_name = 'notebook'\n",
    "\n",
    "# Collect simple parameters from globals\n",
    "_params = {\n",
    "    k: v for k, v in globals().items()\n",
    "    if not k.startswith('_') and isinstance(v, (int, float, str, bool, list, dict, tuple))\n",
    "}\n",
    "pathlib.Path('../results').mkdir(exist_ok=True)\n",
    "with open(f\"../results/{nb_name}_params.json\", 'w') as f:\n",
    "    json.dump(_params, f, indent=2, default=str)\n",
    "if 'results' in globals():\n",
    "    try:\n",
    "        with open(f\"../results/{nb_name}_results.json\", 'w') as f:\n",
    "            json.dump(results, f, indent=2)\n",
    "    except TypeError:\n",
    "        pass\n",
    "print(json.dumps(_params, indent=2, default=str))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "for i, num in enumerate(plt.get_fignums(), start=1):\n",
    "    plt.figure(num)\n",
    "    plt.savefig(FIGURES_DIR / f'{NB_NAME}_plot{i}.png')\n",
    "for _name, _obj in globals().items():\n",
    "    if isinstance(_obj, pd.DataFrame):\n",
    "        _obj.to_csv(RESULTS_DIR / f'{NB_NAME}_{_name}.csv', index=False)\n",
    "        try:\n",
    "            _obj.to_latex(RESULTS_DIR / f'{NB_NAME}_{_name}.tex', index=False)\n",
    "        except Exception:\n",
    "            pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}